{
 "metadata": {
  "name": "",
  "signature": "sha256:64ee223721c7a505b49a22748c2989acd0d8bb02d6c23de9a37bc66907db1274"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn import preprocessing\n",
      "from sklearn.pipeline import Pipeline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_csv('wine.data',header=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = data.iloc[:,0]\n",
      "x = data.iloc[:,1:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1. Classify the raw data using a linear SVM. Do you need to perform several\n",
      "binary classifications or does scikit-learn support multi-class classification\n",
      "with SVMs?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Scikit-learn SVM supporst multi-class classification with both SVC and LinearSVC "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = LinearSVC()\n",
      "print model.fit(x,y)\n",
      "print model.score(x,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)\n",
        "0.887640449438\n"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = SVC()\n",
      "print model.fit(x,y)\n",
      "print model.score(x,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 162
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2. Cross validate the result"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cross_validate(X, y, classifier, k_fold):\n",
      "    k_fold_indices = KFold(len(X), n_folds=k_fold, shuffle=True, random_state=0)\n",
      "    train_score = 0\n",
      "    test_score = 0\n",
      "    for train, test in k_fold_indices:\n",
      "        classifier.fit(X[train],y[train])\n",
      "        train_score += classifier.score(X[train], y[train])\n",
      "        test_score += classifier.score(X[test], y[test])\n",
      "    print \"train score: \" +str(train_score/k_fold)\n",
      "    print \"test_score: \" + str(test_score/k_fold)\n",
      "    print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_validate(x.values,y,LinearSVC(),20)\n",
      "cross_validate(x.values,y,SVC(),20)\n",
      "print \"linearSVC has good results but regualr SVC is only slightly better than random chance\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train score: 0.858686042464\n",
        "test_score: 0.836111111111\n",
        "\n",
        "train score: 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.454861111111\n",
        "\n",
        "linearSVC has good results but regualr SVC is only slightly better than random chance\n"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3. Preprocess the data with a normalization step"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_scaled = preprocessing.scale(x)\n",
      "X_norm = preprocessing.normalize(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "4. Repeat the classification performed in step 1 using a linear SVM and\n",
      "crossvalidate the result. Is it better or worse"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_validate(X_scaled,y,LinearSVC(),10)\n",
      "cross_validate(X_scaled,y,SVC(),10)\n",
      "cross_validate(X_norm,y,LinearSVC(),10)\n",
      "cross_validate(X_norm,y,SVC(),10)\n",
      "print \"scaling worked really well with scores of over 98% accuracy. Normalizing was worse than doing nothing\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train score: 1.0\n",
        "test_score: 0.988888888889\n",
        "\n",
        "train score: 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.983006535948\n",
        "\n",
        "train score: 0.636071428571"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.633333333333\n",
        "\n",
        "train score: 0.39887810559"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.399019607843\n",
        "\n",
        "scaling worked really well with scores of over 98% accuracy. Normalizing was worse than doing nothing\n"
       ]
      }
     ],
     "prompt_number": 178
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5. implement a pipeline that comprises:\n",
      "- a preprocessing step\n",
      "- a classification step"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norms = [preprocessing.Normalizer(), preprocessing.StandardScaler()]\n",
      "svms = [SVC(),LinearSVC()]\n",
      "for norm in norms:\n",
      "    for svm in svms:\n",
      "        estimators = [('normalize', norm), ('svm', svm)]\n",
      "        clf = Pipeline(estimators)\n",
      "        print \"Normalize: \" + str(norm)\n",
      "        print \"SVM: \" + str(svm)\n",
      "        cross_validate(x.values,y,clf,20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Normalize: Normalizer(copy=True, norm='l2')\n",
        "SVM: SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "train score: 0.398875739645"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.398611111111\n",
        "\n",
        "Normalize: Normalizer(copy=True, norm='l2')\n",
        "SVM: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)\n",
        "train score: 0.635421162548"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.634027777778\n",
        "\n",
        "Normalize: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "SVM: SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "train score: 0.999704142012"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.983333333333\n",
        "\n",
        "Normalize: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "SVM: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)\n",
        "train score: 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.977777777778\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "6. Try varying the value of C or the type of kernel. Do you get better results?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norms = [preprocessing.Normalizer(), preprocessing.StandardScaler()]\n",
      "Cs = [.1,2,5,10,20]\n",
      "for C in Cs:\n",
      "    svms = [SVC(C=C),LinearSVC(C=C)]\n",
      "    for norm in norms:\n",
      "        for svm in svms:\n",
      "            estimators = [('normalize', norm), ('svm', svm)]\n",
      "            clf = Pipeline(estimators)\n",
      "            print \"Normalize: \" + str(norm)\n",
      "            print \"SVM: \" + str(svm)\n",
      "            cross_validate(x.values,y,clf,10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Normalize: Normalizer(copy=True, norm='l2')\n",
        "SVM: SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "train score: 0.39887810559"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.399019607843\n",
        "\n",
        "Normalize: Normalizer(copy=True, norm='l2')\n",
        "SVM: LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)\n",
        "train score: 0.531129658385\n",
        "test_score: 0.466666666667\n",
        "\n",
        "Normalize: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "SVM: SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "train score: 0.985636645963"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.971895424837\n",
        "\n",
        "Normalize: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "SVM: LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)\n",
        "train score: 1.0\n",
        "test_score: 0.994444444444\n",
        "\n",
        "Normalize: Normalizer(copy=True, norm='l2')\n",
        "SVM: SVC(C=2, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "train score: 0.39887810559"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.399019607843\n",
        "\n",
        "Normalize: Normalizer(copy=True, norm='l2')\n",
        "SVM: LinearSVC(C=2, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)\n",
        "train score: 0.631071428571"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.627777777778\n",
        "\n",
        "Normalize: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "SVM: SVC(C=2, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "train score: 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.988888888889\n",
        "\n",
        "Normalize: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "SVM: LinearSVC(C=2, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)\n",
        "train score: 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.983333333333\n",
        "\n",
        "Normalize: Normalizer(copy=True, norm='l2')\n",
        "SVM: SVC(C=5, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "train score: 0.39887810559"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.399019607843\n",
        "\n",
        "Normalize: Normalizer(copy=True, norm='l2')\n",
        "SVM: LinearSVC(C=5, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)\n",
        "train score: 0.632942546584"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.627777777778\n",
        "\n",
        "Normalize: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "SVM: SVC(C=5, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "train score: 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.988888888889\n",
        "\n",
        "Normalize: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "SVM: LinearSVC(C=5, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)\n",
        "train score: 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.983333333333\n",
        "\n",
        "Normalize: Normalizer(copy=True, norm='l2')\n",
        "SVM: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "train score: 0.502985248447"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.427450980392\n",
        "\n",
        "Normalize: Normalizer(copy=True, norm='l2')\n",
        "SVM: LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)\n",
        "train score: 0.642930900621"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.633333333333\n",
        "\n",
        "Normalize: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "SVM: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "train score: 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.988888888889\n",
        "\n",
        "Normalize: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "SVM: LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)\n",
        "train score: 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.977777777778\n",
        "\n",
        "Normalize: Normalizer(copy=True, norm='l2')\n",
        "SVM: SVC(C=20, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "train score: 0.626708074534"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.633660130719\n",
        "\n",
        "Normalize: Normalizer(copy=True, norm='l2')\n",
        "SVM: LinearSVC(C=20, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)\n",
        "train score: 0.68163431677"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.666993464052\n",
        "\n",
        "Normalize: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "SVM: SVC(C=20, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "train score: 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.988888888889\n",
        "\n",
        "Normalize: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "SVM: LinearSVC(C=20, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)\n",
        "train score: 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_score: 0.977777777778\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 199
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The best performance was Linear SVC with C = 0.1 using StandardScaler to normalize with a score of .994. Interestingly, all the other models performed better with much higher values for C. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimators = [('normalize', preprocessing.Normalizer()), ('svm', LinearSVC())]\n",
      "clf = Pipeline(estimators)\n",
      "cross_validate(x.values,y,clf,20)\n",
      "print clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train score: 0.635421162548\n",
        "test_score: 0.634027777778\n",
        "\n",
        "Pipeline(steps=[('normalize', Normalizer(copy=True, norm='l2')), ('svm', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0))])\n"
       ]
      }
     ],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimators = [('normalize', preprocessing.StandardScaler()), ('svm', LinearSVC())]\n",
      "clf = Pipeline(estimators)\n",
      "cross_validate(x.values,y,clf,20)\n",
      "print clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train score: 1.0\n",
        "test_score: 0.977777777778\n",
        "\n",
        "Pipeline(steps=[('normalize', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0))])\n"
       ]
      }
     ],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.decomposition import PCA\n",
      "estimators = [('reduce_dim', preprocessing.scale), ('svm', LinearSVC())]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 100,
       "text": [
        "Pipeline(steps=[('reduce_dim', PCA(copy=True, n_components=None, whiten=False)), ('svm', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0))])"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_validate(x.values,y,clf,20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train score: 0.635421162548\n",
        "test_score: 0.634027777778\n"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}